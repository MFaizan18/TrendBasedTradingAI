{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2024 Mohammed Faizan\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.trend import EMAIndicator\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from datetime import datetime\n",
    "import math \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training windows: 2595\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPROCESSING\n",
    "\n",
    "# Download stock price data\n",
    "data = yf.download(\"^NSEI\", start=\"2010-01-01\", end=\"2024-05-25\", interval=\"1d\")\n",
    "\n",
    "# Calculate RSI\n",
    "rsi_indicator = RSIIndicator(close=data['Adj Close'], window=14)\n",
    "data['RSI'] = rsi_indicator.rsi()\n",
    "\n",
    "# Calculate 50-day EMA\n",
    "ema_indicator = EMAIndicator(close=data['Adj Close'], window=50)\n",
    "data['50_EMA'] = ema_indicator.ema_indicator()\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Drop the 'Close' column\n",
    "data = data.drop(columns=['Close'])\n",
    "\n",
    "# Store dates in a separate DataFrame\n",
    "dates = data.index.to_frame(index=False)\n",
    "\n",
    "# Reset index\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Divide the data into training and test data based on the date\n",
    "training_data = data[dates['Date'].dt.year <= 2020].copy()\n",
    "#print(training_data.head(5))\n",
    "test_data = data[dates['Date'].dt.year > 2020].copy()\n",
    "\n",
    "# Define the window lengths for the antecedent and consequent parts\n",
    "wtr = 50  # total window length\n",
    "wte = 40  # window length for the antecedent part\n",
    "wlm = wtr - wte  # window length for the consequent part\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Create and normalize the antecedent parts for the training data\n",
    "training_windows = [training_data[i:i + wtr] for i in range(len(training_data) - wtr + 1)]\n",
    "training_windows_antece_normalized = [np.concatenate([scaler.fit_transform(window.iloc[:wte]), window.iloc[wte:wtr]], axis=0) for window in training_windows]\n",
    "\n",
    "# Print the number of windows\n",
    "print(f\"Number of training windows: {len(training_windows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty clusters: 0\n"
     ]
    }
   ],
   "source": [
    "# K- MEANS CLUSTERING\n",
    "\n",
    "def k_means_clustering(data, k, max_iterations=500, random_state=0):\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Initialize centroids randomly from the data points\n",
    "    centroids = data[np.random.choice(len(data), size=k, replace=False)]\n",
    "    \n",
    "    for _ in range(max_iterations):\n",
    "        # Assign each data point to the nearest cluster center\n",
    "        distances = np.linalg.norm(data.reshape(len(data), -1)[:, np.newaxis] - centroids.reshape(len(centroids), -1), axis=2)\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "\n",
    "        # Recalculate the centroids as the mean of the current clusters\n",
    "        new_centroids = np.empty_like(centroids)\n",
    "        empty_clusters = 0\n",
    "        for i in range(k):\n",
    "            members = data[labels == i]\n",
    "            if len(members) > 0:\n",
    "                new_centroids[i] = np.mean(members, axis=0)\n",
    "            else:\n",
    "                new_centroids[i] = centroids[i]\n",
    "                #new_centroids[i] = data[np.random.randint(len(data))]\n",
    "                empty_clusters += 1\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.array_equal(centroids, new_centroids):\n",
    "            break\n",
    "\n",
    "        centroids = new_centroids\n",
    "\n",
    "    print(f\"Number of empty clusters: {empty_clusters}\")\n",
    "\n",
    "    # Calculate Kronecker delta function\n",
    "    delta = np.zeros((len(data), k))\n",
    "    for i in range(len(data)):\n",
    "        delta[i, labels[i]] = 1\n",
    "\n",
    "    return labels, centroids, delta\n",
    "\n",
    "k = 50 # number of clusters\n",
    "\n",
    "# Extract the antecedent part from each window\n",
    "antecedent_windows = [window[:wte] for window in training_windows_antece_normalized]\n",
    "\n",
    "# Run K-means clustering on the antecedent windows\n",
    "labels, centroids, delta = k_means_clustering(np.array(antecedent_windows), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'UP' labels: 50\n",
      "Number of 'DOWN' labels: 0\n"
     ]
    }
   ],
   "source": [
    "# LABELLING THE CLUSTERS \n",
    " \n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Initialize the trend labels\n",
    "cluster_trends = {}\n",
    "\n",
    "# Convert the list to a numpy array and flatten it to 2D\n",
    "data_array = np.array(training_windows_antece_normalized).reshape(len(training_windows_antece_normalized), -1)\n",
    "\n",
    "# For each cluster\n",
    "for j in range(k):\n",
    "    # Get the windows that belong to the cluster\n",
    "   \n",
    "    windows = data_array[delta[:, j] == 1]\n",
    "    \n",
    "    # If the cluster has no windows, skip it\n",
    "    if len(windows) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Initialize an empty list to store the consequent parts\n",
    "    consequent_parts = []\n",
    "    \n",
    "    # For each window in the cluster\n",
    "    for window in windows:\n",
    "        # Get the consequent part of the window\n",
    "        consequent_part = window[wte:]\n",
    "        \n",
    "        # Add the consequent part to the list\n",
    "        consequent_parts.append(consequent_part)\n",
    "    \n",
    "    # Combine the consequent parts of all windows in the cluster\n",
    "    combined_consequent_part = np.concatenate(consequent_parts)\n",
    "    \n",
    "    # Fit the linear regression model\n",
    "    t = np.arange(len(combined_consequent_part)).reshape(-1, 1)  # This is t\n",
    "    model.fit(t, combined_consequent_part)  # This calculates a and b\n",
    "\n",
    "    # Get the slope of the model\n",
    "    slope = model.coef_[0]  # This is b\n",
    "\n",
    "    # Assign the trend label based on the slope\n",
    "    if slope > 0:\n",
    "        cluster_trends[j] = \"UP\"\n",
    "    else:\n",
    "        cluster_trends[j] = \"DOWN\"\n",
    "\n",
    "# Count the number of \"UP\" labels\n",
    "num_up = list(cluster_trends.values()).count(\"UP\")\n",
    "\n",
    "# Count the number of \"DOWN\" labels\n",
    "num_down = list(cluster_trends.values()).count(\"DOWN\")\n",
    "\n",
    "# Print the counts\n",
    "print(\"Number of 'UP' labels:\", num_up)\n",
    "print(\"Number of 'DOWN' labels:\", num_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of windows: 798\n",
      "Counter({'UP': 798})\n"
     ]
    }
   ],
   "source": [
    "# LABELLING THE TEST DATA WINDOWS\n",
    "\n",
    "antecedent_size = 40\n",
    "\n",
    "# Create a separate DataFrame for the test dates\n",
    "test_dates = dates[dates['Date'].dt.year > 2020].copy()\n",
    "\n",
    "# Create windows for the test data\n",
    "test_windows = [test_data[i:i + antecedent_size] for i in range(len(test_data) - antecedent_size + 1)]\n",
    "\n",
    "# Normalize each window\n",
    "test_windows_normalized = [scaler.transform(window) for window in test_windows]\n",
    "\n",
    "# Print the total number of windows\n",
    "print(f\"Total number of windows: {len(test_windows)}\")\n",
    "\n",
    "# Initialize the trend labels for the test data\n",
    "test_trend_labels = []\n",
    "\n",
    "# For each window in the test data\n",
    "for window in test_windows_normalized:\n",
    "    \n",
    "    # Calculate the Euclidean distance to each cluster center\n",
    "    distances = np.linalg.norm(centroids - window, axis=1)\n",
    "\n",
    "    # Find the index of the closest cluster center\n",
    "    closest_cluster = np.argmin(distances)\n",
    "\n",
    "    # Check if the closest cluster index is a valid index for the labels array\n",
    "    if closest_cluster < len(labels):\n",
    "        # Assign the trend label of the closest cluster to the window\n",
    "        test_trend_labels.append(cluster_trends[labels[closest_cluster]])\n",
    "    else:\n",
    "        # If the closest cluster index is not a valid index for the labels array, print an error message\n",
    "        print(f\"Error: closest cluster index {closest_cluster} is not a valid index for the labels array.\")\n",
    "\n",
    "# Import the Counter class from the collections module\n",
    "from collections import Counter\n",
    "\n",
    "# Count the number of each label in test_trend_labels\n",
    "label_counts = Counter(test_trend_labels)\n",
    "\n",
    "# Print the counts\n",
    "print(label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return for 2021: 15.852735476040047%\n",
      "Number of Buy actions in 2021: 247\n",
      "Number of Sell actions in 2021: 1\n",
      "Return for 2022: -2.485190345751953%\n",
      "Number of Buy actions in 2022: 247\n",
      "Number of Sell actions in 2022: 1\n",
      "Return for 2023: 20.92553105589845%\n",
      "Number of Buy actions in 2023: 244\n",
      "Number of Sell actions in 2023: 1\n",
      "Return for 2024: 5.400270834062515%\n",
      "Number of Buy actions in 2024: 56\n",
      "Number of Sell actions in 2024: 1\n"
     ]
    }
   ],
   "source": [
    "# TRADNG STRATEGY\n",
    "\n",
    "# Define the cost\n",
    "c = 0.00135\n",
    "\n",
    "# Define the years\n",
    "years = [2021, 2022, 2023, 2024]\n",
    "\n",
    "# Initialize a list to store the final value of your portfolio for each year\n",
    "final_values = []\n",
    "\n",
    "# For each year\n",
    "for year in years:\n",
    "    # Initialize the amount of money you have and the number of shares you own\n",
    "    money = 1000000.0\n",
    "    shares = 0\n",
    "\n",
    "    # Initialize a list to store trading actions\n",
    "    actions = []\n",
    "\n",
    "    # Get the indices for the current year\n",
    "    indices_year = [i for i, date in enumerate(test_dates['Date']) if date.year == year and i < len(test_windows)]\n",
    "    \n",
    "\n",
    "    # Get the test windows and trend labels for the current year\n",
    "    test_windows_year = [test_windows[i] for i in indices_year]\n",
    "    test_trend_labels_year = [test_trend_labels[i] for i in indices_year]\n",
    "\n",
    "    # For each window in the test data for the current year\n",
    "    for i in range(len(test_windows_year)):\n",
    "        # Calculate the current stock price\n",
    "        current_price = test_windows_year[i].iloc[0]['Adj Close']\n",
    "\n",
    "        # Check the trend label for the current window\n",
    "        current_trend_label = test_trend_labels_year[i]\n",
    "\n",
    "        if current_trend_label == \"UP\" :\n",
    "            # If the current window is \"UP\", buy shares at the beginning of the next window\n",
    "            if i + 1 < len(test_windows_year):\n",
    "                next_price = test_windows_year[i + 1].iloc[0]['Adj Close']\n",
    "                shares_to_buy = math.floor((0.25 * money) / (next_price * (1 + c)))\n",
    "                money -= shares_to_buy * next_price * (1 + c)\n",
    "                shares += shares_to_buy\n",
    "                actions.append(\"Buy\")\n",
    "\n",
    "        elif current_trend_label == \"DOWN\" and shares > 0:\n",
    "            # If the current window is \"DOWN\", sell all shares at the beginning of the next window\n",
    "            if i + 1 < len(test_windows_year):\n",
    "                next_price = test_windows_year[i + 1].iloc[0]['Adj Close']\n",
    "                money += shares * next_price * (1 - c)\n",
    "                shares = 0\n",
    "                actions.append(\"Sell\")\n",
    "\n",
    "    # Sell any shares left at the end of the last day\n",
    "    if shares > 0:\n",
    "        sell_price = test_windows_year[-1].iloc[-1]['Adj Close']\n",
    "        money += shares * sell_price * (1 - c)\n",
    "        shares = 0\n",
    "        actions.append(\"Sell\")\n",
    "\n",
    "    # Calculate the final value of your portfolio\n",
    "    final_value = money\n",
    "\n",
    "    # Store the final value\n",
    "    final_values.append(final_value)\n",
    "\n",
    "    # Calculate the return\n",
    "    return_percentage = (final_value / 1000000.0 - 1) * 100\n",
    "\n",
    "    # Print the return\n",
    "    print(f\"Return for {year}: {return_percentage}%\")\n",
    "\n",
    "    # Count the number of each action\n",
    "    buy_count = actions.count(\"Buy\")\n",
    "    sell_count = actions.count(\"Sell\")\n",
    "    #stay_count = actions.count(\"Stay\")\n",
    "\n",
    "    # Print the counts\n",
    "    print(f\"Number of Buy actions in {year}: {buy_count}\")\n",
    "    print(f\"Number of Sell actions in {year}: {sell_count}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio: -0.19615086118801492\n"
     ]
    }
   ],
   "source": [
    "# Risk-free rate\n",
    "risk_free_rate = 0.02  # Annual risk-free rate (2%)\n",
    "\n",
    "# Calculate the annual returns\n",
    "returns = [(final_values[i] / final_values[i-1]) - 1 for i in range(1, len(final_values))]\n",
    "\n",
    "# Calculate the excess returns (subtracting the risk-free rate from each return)\n",
    "excess_returns = [r - risk_free_rate for r in returns]\n",
    "\n",
    "# Calculate the average excess return\n",
    "average_excess_return = np.mean(excess_returns)\n",
    "\n",
    "# Calculate the standard deviation of the excess returns\n",
    "standard_deviation = np.std(excess_returns)\n",
    "\n",
    "# Calculate the Sharpe Ratio\n",
    "sharpe_ratio = average_excess_return / standard_deviation\n",
    "\n",
    "print(f\"Sharpe Ratio: {sharpe_ratio}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
